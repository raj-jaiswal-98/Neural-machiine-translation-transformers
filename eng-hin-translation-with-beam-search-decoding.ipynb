{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64504682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:11.082513Z",
     "iopub.status.busy": "2023-05-12T14:23:11.082083Z",
     "iopub.status.idle": "2023-05-12T14:23:23.207374Z",
     "shell.execute_reply": "2023-05-12T14:23:23.205609Z"
    },
    "papermill": {
     "duration": 12.141885,
     "end_time": "2023-05-12T14:23:23.209562",
     "exception": false,
     "start_time": "2023-05-12T14:23:11.067677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -q bpemb  # byte pair encoding module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a63bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:23.237118Z",
     "iopub.status.busy": "2023-05-12T14:23:23.235671Z",
     "iopub.status.idle": "2023-05-12T14:23:34.590514Z",
     "shell.execute_reply": "2023-05-12T14:23:34.589413Z"
    },
    "papermill": {
     "duration": 11.370489,
     "end_time": "2023-05-12T14:23:34.592642",
     "exception": false,
     "start_time": "2023-05-12T14:23:23.222153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9b99f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:34.619430Z",
     "iopub.status.busy": "2023-05-12T14:23:34.619086Z",
     "iopub.status.idle": "2023-05-12T14:23:39.144606Z",
     "shell.execute_reply": "2023-05-12T14:23:39.143656Z"
    },
    "papermill": {
     "duration": 4.541226,
     "end_time": "2023-05-12T14:23:39.146677",
     "exception": false,
     "start_time": "2023-05-12T14:23:34.605451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from bpemb import BPEmb\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e190833d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:39.175070Z",
     "iopub.status.busy": "2023-05-12T14:23:39.173198Z",
     "iopub.status.idle": "2023-05-12T14:23:48.562218Z",
     "shell.execute_reply": "2023-05-12T14:23:48.561317Z"
    },
    "papermill": {
     "duration": 9.405111,
     "end_time": "2023-05-12T14:23:48.564576",
     "exception": false,
     "start_time": "2023-05-12T14:23:39.159465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  \n",
       "0  Give your application an accessibility workout  \n",
       "1               Accerciser Accessibility Explorer  \n",
       "2  The default plugin layout for the bottom panel  \n",
       "3     The default plugin layout for the top panel  \n",
       "4  A list of plugins that are disabled by default  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('hindi_english_parallel.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8e4335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:48.592429Z",
     "iopub.status.busy": "2023-05-12T14:23:48.592115Z",
     "iopub.status.idle": "2023-05-12T14:23:52.268997Z",
     "shell.execute_reply": "2023-05-12T14:23:52.267525Z"
    },
    "papermill": {
     "duration": 3.693208,
     "end_time": "2023-05-12T14:23:52.271055",
     "exception": false,
     "start_time": "2023-05-12T14:23:48.577847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1353912 entries, 0 to 1561839\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count    Dtype \n",
      "---  ------   --------------    ----- \n",
      " 0   hindi    1353912 non-null  object\n",
      " 1   english  1353912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae6a6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:52.299371Z",
     "iopub.status.busy": "2023-05-12T14:23:52.299045Z",
     "iopub.status.idle": "2023-05-12T14:23:56.814503Z",
     "shell.execute_reply": "2023-05-12T14:23:56.811215Z"
    },
    "papermill": {
     "duration": 4.532944,
     "end_time": "2023-05-12T14:23:56.817842",
     "exception": false,
     "start_time": "2023-05-12T14:23:52.284898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>english_len</th>\n",
       "      <th>hindi_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  english_len  hindi_len  \n",
       "0  Give your application an accessibility workout            6          8  \n",
       "1               Accerciser Accessibility Explorer            3          3  \n",
       "2  The default plugin layout for the bottom panel            8          7  \n",
       "3     The default plugin layout for the top panel            8          7  \n",
       "4  A list of plugins that are disabled by default            9         12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['english_len'] = data['english'].apply(lambda x:len(x.split()))\n",
    "data['hindi_len'] = data['hindi'].apply(lambda x:len(x.split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533ecd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:56.865785Z",
     "iopub.status.busy": "2023-05-12T14:23:56.865345Z",
     "iopub.status.idle": "2023-05-12T14:23:56.953116Z",
     "shell.execute_reply": "2023-05-12T14:23:56.952205Z"
    },
    "papermill": {
     "duration": 0.118226,
     "end_time": "2023-05-12T14:23:56.957377",
     "exception": false,
     "start_time": "2023-05-12T14:23:56.839151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>english_len</th>\n",
       "      <th>hindi_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...</td>\n",
       "      <td>The duration of the highlight box when selecti...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "6  पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...   \n",
       "\n",
       "                                             english  english_len  hindi_len  \n",
       "0     Give your application an accessibility workout            6          8  \n",
       "2     The default plugin layout for the bottom panel            8          7  \n",
       "3        The default plugin layout for the top panel            8          7  \n",
       "4     A list of plugins that are disabled by default            9         12  \n",
       "6  The duration of the highlight box when selecti...           10         10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data.english_len>=5) & (data.english_len<=15) & (data.hindi_len>=5) & (data.hindi_len<=15)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6279ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:57.001860Z",
     "iopub.status.busy": "2023-05-12T14:23:57.001476Z",
     "iopub.status.idle": "2023-05-12T14:23:57.042235Z",
     "shell.execute_reply": "2023-05-12T14:23:57.041277Z"
    },
    "papermill": {
     "duration": 0.065714,
     "end_time": "2023-05-12T14:23:57.045343",
     "exception": false,
     "start_time": "2023-05-12T14:23:56.979629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.sample(n=25000, random_state=0)\n",
    "train_split, test_split = train_test_split(data, test_size=0.1, random_state=0)\n",
    "train_split = train_split.reset_index(0).drop(['index'], axis=1)\n",
    "test_split = test_split.reset_index(0).drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d5246a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:57.086467Z",
     "iopub.status.busy": "2023-05-12T14:23:57.086095Z",
     "iopub.status.idle": "2023-05-12T14:23:57.103691Z",
     "shell.execute_reply": "2023-05-12T14:23:57.102874Z"
    },
    "papermill": {
     "duration": 0.040655,
     "end_time": "2023-05-12T14:23:57.106538",
     "exception": false,
     "start_time": "2023-05-12T14:23:57.065883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500 2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>english_len</th>\n",
       "      <th>hindi_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>एक खूब छोटा अंश जिस में तत्वों के गुण होते है।</td>\n",
       "      <td>A very small component acquiring a quality of ...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>कोटा जानकारी समर्थित नहीं फ़ोल्डर '% s' के लिए</td>\n",
       "      <td>No IMAP mailbox available for folder '% s'</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>परन्तु यह शीघ्र ही अपर्याप्त प्रतीत हुआ...।</td>\n",
       "      <td>But soon this was found rather inadequate.</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>उसने गिरफ्तार व्यक्ति के लिए प्रतिभू की भूमिका...</td>\n",
       "      <td>He acted as ad - promisor for the arrested per...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अल्लाह से क्षमा की प्रार्थना करो। निस्संदेह अल...</td>\n",
       "      <td>Ask God for forgiveness: He is most forgiving ...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    एक खूब छोटा अंश जिस में तत्वों के गुण होते है।    \n",
       "1     कोटा जानकारी समर्थित नहीं फ़ोल्डर '% s' के लिए   \n",
       "2       परन्तु यह शीघ्र ही अपर्याप्त प्रतीत हुआ...।    \n",
       "3  उसने गिरफ्तार व्यक्ति के लिए प्रतिभू की भूमिका...   \n",
       "4  अल्लाह से क्षमा की प्रार्थना करो। निस्संदेह अल...   \n",
       "\n",
       "                                             english  english_len  hindi_len  \n",
       "0  A very small component acquiring a quality of ...            9         11  \n",
       "1         No IMAP mailbox available for folder '% s'            8          9  \n",
       "2         But soon this was found rather inadequate.            7          7  \n",
       "3  He acted as ad - promisor for the arrested per...           10          9  \n",
       "4  Ask God for forgiveness: He is most forgiving ...           10         12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_split), len(test_split))\n",
    "train_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79dd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:59:14.777540Z",
     "iopub.status.busy": "2023-05-11T06:59:14.777082Z",
     "iopub.status.idle": "2023-05-11T06:59:14.788484Z",
     "shell.execute_reply": "2023-05-11T06:59:14.786870Z",
     "shell.execute_reply.started": "2023-05-11T06:59:14.777505Z"
    },
    "papermill": {
     "duration": 0.019331,
     "end_time": "2023-05-12T14:23:57.149006",
     "exception": false,
     "start_time": "2023-05-12T14:23:57.129675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenization approach\n",
    "One of the ways to perform subword tokenization is Byte-Pair Encoding (BPE, actually it is a data compression algorithm), \n",
    "WordPiece (used by BERT), and SentencePiece \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d9312d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:23:57.188806Z",
     "iopub.status.busy": "2023-05-12T14:23:57.188438Z",
     "iopub.status.idle": "2023-05-12T14:24:04.526844Z",
     "shell.execute_reply": "2023-05-12T14:24:04.525898Z"
    },
    "papermill": {
     "duration": 7.361858,
     "end_time": "2023-05-12T14:24:04.530249",
     "exception": false,
     "start_time": "2023-05-12T14:23:57.168391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is basically the module by which we're gonna perform tokenization according to the Byte-Level Byte Pair Encoding\n",
    "bpemb_en = BPEmb(lang='en')\n",
    "bpemb_hi = BPEmb(lang='hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17173c",
   "metadata": {
    "papermill": {
     "duration": 0.016084,
     "end_time": "2023-05-12T14:24:04.571458",
     "exception": false,
     "start_time": "2023-05-12T14:24:04.555374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0072afec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:04.605283Z",
     "iopub.status.busy": "2023-05-12T14:24:04.604927Z",
     "iopub.status.idle": "2023-05-12T14:24:04.615673Z",
     "shell.execute_reply": "2023-05-12T14:24:04.615025Z"
    },
    "papermill": {
     "duration": 0.029937,
     "end_time": "2023-05-12T14:24:04.617488",
     "exception": false,
     "start_time": "2023-05-12T14:24:04.587551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, max_seq_len=64):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        eng_sen = self.data.english.iloc[index]\n",
    "        hin_sen = self.data.hindi.iloc[index]\n",
    "        eng_tokens = bpemb_en.encode_ids_with_bos_eos(eng_sen)\n",
    "        hin_tokens = bpemb_hi.encode_ids_with_bos_eos(hin_sen)\n",
    "        trg_input_tokens = hin_tokens[:-1]\n",
    "        trg_output_tokens = hin_tokens[1:]\n",
    "        \n",
    "        eng_mask = [1]*(len(eng_tokens))\n",
    "        hin_mask = [1]*(len(trg_input_tokens))\n",
    "        \n",
    "        eng_tokens = eng_tokens + [0]*(self.max_seq_len - len(eng_tokens))\n",
    "        trg_input_tokens = trg_input_tokens + [0]*(self.max_seq_len - len(trg_input_tokens))\n",
    "        trg_output_tokens = trg_output_tokens + [0]*(self.max_seq_len - len(trg_output_tokens))\n",
    "        \n",
    "        eng_mask = eng_mask + [0]*(self.max_seq_len - len(eng_mask))\n",
    "        hin_mask = hin_mask + [0]*(self.max_seq_len - len(hin_mask))\n",
    "        # pad eng_tokens upto max_seq_len\n",
    "        # pad_hin_tokens upto max_seq_len\n",
    "        # then create masks for both of the inputs, and make them upto the dimension needed\n",
    "        \n",
    "        # now we have to pad the sequence upto max length and create the masks for the same\n",
    "        \n",
    "        \n",
    "        return torch.tensor(eng_tokens), torch.tensor(trg_input_tokens), torch.tensor(trg_output_tokens), torch.tensor(eng_mask), torch.tensor(hin_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7be77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T06:19:32.852927Z",
     "iopub.status.busy": "2023-05-09T06:19:32.852547Z",
     "iopub.status.idle": "2023-05-09T06:19:32.862981Z",
     "shell.execute_reply": "2023-05-09T06:19:32.861836Z",
     "shell.execute_reply.started": "2023-05-09T06:19:32.852900Z"
    },
    "papermill": {
     "duration": 0.016132,
     "end_time": "2023-05-12T14:24:04.649919",
     "exception": false,
     "start_time": "2023-05-12T14:24:04.633787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoder\n",
    "So the solution is 'throw all recurrence and base EACH encoder OUTPUT on all the ENCODER INPUTS', so the solution is \n",
    "self-attention.\n",
    "For example let there be n inputs, vocab_size be 10, and embedding_dim be m, so our first we have to get the attention weights\n",
    "which will be like - softmax([<xj,x1>, <xj, x2>,...,  <xj,xn>]) and the new resultant vector is x_i = sum(a_ij*x_j) which will\n",
    "be of shape n again.\n",
    "Now due to this type of mechanism we can avoid recurrence, and get all the attention based outputs in just a single pass. \n",
    "By just multiplying the matrices as softmax(X@X.T, axis=0) (if input is of shape n ,embedding_dim where n i sthe number of\n",
    "time_steps or seq_len). (Note that this is for one senetence only). \n",
    "And we can stack attention as they are of the same shape. \n",
    "\n",
    "But the probelm in above task is that, we don't have any learnable weights, so we have to rely only on the quality of \n",
    "embeddingss, so we insert weights in the scenario and it becomes scaled dot product self-attention.\n",
    "\n",
    "\n",
    "Attention(Q, K, V) = softmax(Q@K.T/sqrt(d_k))V, where Q = X@W_q, K = X@W_k, V = X@W_v.  And each of W_q, W_k, W_v is of shape \n",
    "dxd and X is of shape (txd). This is known as attention single head. Scaling in this helps in preventing the exploding \n",
    "gradient problem. \n",
    "\n",
    "Now there is still a problem in the above implementation as the self attention is going to give the most weight to one of the \n",
    "embedding_dimension, but there can be multiple informations in a single statement, like 'I went to a restaurant to meet my \n",
    "freind that night', there are questions, 'why, where, who, when'. So. we require multiple such attentions so that our \n",
    "attention mechanism takes care of all such queries, so the solution is multi-headed attention, in this method we take\n",
    "separate weights for W_q, W_k, W_v for each of the single heads, but the catch over here is that each of matrix W_q, W_k, W_v\n",
    "is of the shape is (dxd/h), thus the computational cost is still same as single headed attention. And then, the outputs from \n",
    "all the heads are then passed concatenated and passed through a feed forward network. \n",
    "\n",
    "In all this mechanism, we got the information on how the words are dependent on one another, but we lost the positional \n",
    "information, so here comes the positional encoding for rescue. We will add the positional embedding layer (which can be treated\n",
    "as learnable weights) and it is of the same shape as our inputs.\n",
    "\n",
    "Now there is no non-linearity in the system, thus we have to introduce one, so we insert feedforward networks after mutli-head\n",
    "self attention with non-linear activation functions, now all this multihead + feedforward is reffered as an encoder block, and \n",
    "we can stack these blocks.\n",
    "\n",
    "But stacking brings another problem, i.e., the positional informations gets lost over if multiple encoder blocks are used and \n",
    "this also leads to vanishing gradient problem.\n",
    "\n",
    "\n",
    "And the solutions to both these problems are LayerNormalization in between feedforward networks and skip-connections between \n",
    "the blocks (same as resnet).\n",
    "\n",
    "\n",
    "# Decoder\n",
    "In decoder, we can apply the same process, but there is a issue, as in encoder, we have the all the input sentence at one time,\n",
    "but in decoding practically, we have only the previous time steps, so we have to somwhow zero the attention weights given to \n",
    "the subsequent words in the sentence. Thus we have to mask them. Thus, it is known as masked smulti-head self attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce2cb4",
   "metadata": {
    "papermill": {
     "duration": 0.015793,
     "end_time": "2023-05-12T14:24:04.681653",
     "exception": false,
     "start_time": "2023-05-12T14:24:04.665860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shapes of inputs and outputs of different layers\n",
    "m - number of examples or batch_size if batched inputs\n",
    "\n",
    "t - sequence length or can say number of time steps\\\n",
    "\n",
    "d - model shape, or embedding dimension shape \n",
    "\n",
    "h - number of heads\n",
    "\n",
    "Then, \n",
    "\n",
    "1. input shape - (m, t, d)\n",
    "2. W_q, W_k, W_v - (d, d/h)\n",
    "3. Q,K,V shapes - XW_q.shape i.e. (m, t, d/h)\n",
    "4. Shape of K.T will be (m, d/h, t)\n",
    "5. Output from single head - softmax(Q@K.T/sqrt(d_k)) where d_k = d/h, will be - (m, t, d/h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e8febe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:04.715445Z",
     "iopub.status.busy": "2023-05-12T14:24:04.714758Z",
     "iopub.status.idle": "2023-05-12T14:24:04.722182Z",
     "shell.execute_reply": "2023-05-12T14:24:04.721348Z"
    },
    "papermill": {
     "duration": 0.026553,
     "end_time": "2023-05-12T14:24:04.724180",
     "exception": false,
     "start_time": "2023-05-12T14:24:04.697627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    # this is going in the single head self-attention.\n",
    "    # query, key, value shape will be (b, h, t, d/h) \n",
    "    d_k = query.shape[-1]\n",
    "    scaled_scores = torch.matmul(query, torch.transpose(key, -2, -1))/np.sqrt(d_k)  # shape is  (b, h, t, t)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # mask must be of shape (b,h,t,t)\n",
    "        scaled_scores = torch.where(mask==0, -np.inf, scaled_scores)\n",
    "        \n",
    "    weights = torch.nn.Softmax(dim=-1)(scaled_scores) # shape is (b,h,t,t)\n",
    "    return torch.matmul(weights, value)  # shape will be (b,h,t,d/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831687b1",
   "metadata": {
    "papermill": {
     "duration": 0.016336,
     "end_time": "2023-05-12T14:24:05.099951",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.083615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfc3e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.134551Z",
     "iopub.status.busy": "2023-05-12T14:24:05.133806Z",
     "iopub.status.idle": "2023-05-12T14:24:05.144427Z",
     "shell.execute_reply": "2023-05-12T14:24:05.143592Z"
    },
    "papermill": {
     "duration": 0.029965,
     "end_time": "2023-05-12T14:24:05.146392",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.116427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # let us say that our input is of shape (b, t, d) \n",
    "        self.wq = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False) \n",
    "        self.wk = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False)\n",
    "        self.wv = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False)\n",
    "        # remember that wq, wk, ev defined above are just the matrices nothing more\n",
    "        \n",
    "        # now the final dense layer to add some nolinearity in it \n",
    "        self.fc = nn.Linear(self.d_model, self.d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # shape of q, k, v is (b, t, d)\n",
    "        q = self.wq(q).reshape(q.shape[0], q.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n",
    "        k = self.wk(k).reshape(k.shape[0], k.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n",
    "        v = self.wv(v).reshape(v.shape[0], v.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n",
    "        \n",
    "        # now shape of q, k, v is (b, h, t, d/h)\n",
    "        # now we have to simply perform  self-attention for every head\n",
    "        op = scaled_dot_product_attention(q, k, v, mask)  # shape of op is (b, h, t, d/h)\n",
    "        op = op.permute(0, 2, 1, 3)\n",
    "        op = op.reshape(op.shape[0], op.shape[1], self.d_model)  # now shape of op is (b, t, d)\n",
    "        return self.fc(op) # shapes are (b, t, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29395e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.181053Z",
     "iopub.status.busy": "2023-05-12T14:24:05.180344Z",
     "iopub.status.idle": "2023-05-12T14:24:05.186288Z",
     "shell.execute_reply": "2023-05-12T14:24:05.185470Z"
    },
    "papermill": {
     "duration": 0.025247,
     "end_time": "2023-05-12T14:24:05.188268",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.163021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedforward(nn.Module):\n",
    "    def __init__(self, d_model, hidden_dim):\n",
    "        super(feedforward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "752dad23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.222375Z",
     "iopub.status.busy": "2023-05-12T14:24:05.222076Z",
     "iopub.status.idle": "2023-05-12T14:24:05.229799Z",
     "shell.execute_reply": "2023-05-12T14:24:05.228886Z"
    },
    "papermill": {
     "duration": 0.027105,
     "end_time": "2023-05-12T14:24:05.231722",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.204617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n",
    "        super(encoder_block, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.fc = feedforward(d_model, hidden_dim) # gonna give the shapes again to be (b, t, d)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # input shape is (b, t, d)\n",
    "        op = self.mhsa(x, x, x, mask) # op shape is (b, t, d) and attention weights are of shape (b, t, t)\n",
    "        op = self.dropout1(op)\n",
    "        # now we have to pass it through layer normalization (study it)\n",
    "        op = self.layernorm1(op + x)\n",
    "        ffn_op = self.fc(op)\n",
    "        ffn_op = self.dropout2(ffn_op)\n",
    "        op = self.layernorm2(op + ffn_op)\n",
    "        return op\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25c1a091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.266956Z",
     "iopub.status.busy": "2023-05-12T14:24:05.266194Z",
     "iopub.status.idle": "2023-05-12T14:24:05.276004Z",
     "shell.execute_reply": "2023-05-12T14:24:05.275238Z"
    },
    "papermill": {
     "duration": 0.029407,
     "end_time": "2023-05-12T14:24:05.277928",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.248521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoder_transformer(nn.Module):\n",
    "    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len, dropout_rate=0.1):\n",
    "        # max_seq_len is the number of time steps, i'll be referring it as t\n",
    "        super(encoder_transformer, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_dim = hidden_dim \n",
    "        self.vocab_size = src_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.token_embeds = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_embeds = nn.Embedding(max_seq_len, d_model)\n",
    "        self.dropout = nn.Dropout(p = dropout_rate)\n",
    "        self.blocks = nn.ModuleList([encoder_block(d_model, num_heads, hidden_dim, dropout_rate=dropout_rate) \n",
    "                      for _ in range(self.num_blocks)])\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, source, mask=None):\n",
    "        # shape of source is (b, t)\n",
    "        # all source sentences will be padded and padding will be static\n",
    "        source = source.type(torch.LongTensor).to(device)\n",
    "        # comment out above line for \n",
    "        t_embeds = self.token_embeds(source) # (b, t, d)\n",
    "        pos_ids = torch.broadcast_to(torch.arange(self.max_seq_len), (x.shape[0], self.max_seq_len)).type(torch.LongTensor\n",
    "                                                                                                         ).to(device)\n",
    "        p_embeds = self.pos_embeds(pos_ids) # (b, t, d)\n",
    "        \n",
    "        inp = t_embeds + p_embeds  # (b, t, d)\n",
    "        op = self.dropout(inp)  # (b, t, d)\n",
    "        \n",
    "        for _, block in enumerate(self.blocks):\n",
    "            op = block(op, mask)\n",
    "            \n",
    "        return op\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f03a1",
   "metadata": {
    "papermill": {
     "duration": 0.016205,
     "end_time": "2023-05-12T14:24:05.310531",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.294326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da20a9bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.345225Z",
     "iopub.status.busy": "2023-05-12T14:24:05.344483Z",
     "iopub.status.idle": "2023-05-12T14:24:05.353889Z",
     "shell.execute_reply": "2023-05-12T14:24:05.352977Z"
    },
    "papermill": {
     "duration": 0.028736,
     "end_time": "2023-05-12T14:24:05.355844",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.327108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n",
    "        super(decoder_block, self).__init__()\n",
    "        self.mhsa1 = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.mhsa2 = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        \n",
    "        self.fc = feedforward(d_model, hidden_dim)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.dropout3 = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_ouptut, target, decoder_mask=None, memory_mask=None):\n",
    "        mhsa_op1 = self.mhsa1(target, target, target, decoder_mask)\n",
    "        mhsa_op1 = self.dropout1(mhsa_op1)\n",
    "        mhsa_op1 = self.layernorm1(mhsa_op1 + target)\n",
    "        \n",
    "        mhsa_op2 = self.mhsa2(mhsa_op1, encoder_ouptut, encoder_ouptut, memory_mask)\n",
    "        mhsa_op2 = self.dropout2(mhsa_op2)\n",
    "        mhsa_op2 = self.layernorm2(mhsa_op1 + mhsa_op2)\n",
    "        \n",
    "        fc_op = self.fc(mhsa_op2)\n",
    "        fc_op = self.dropout3(fc_op)\n",
    "        op = self.layernorm3(fc_op + mhsa_op2)\n",
    "        \n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "939f5a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.390480Z",
     "iopub.status.busy": "2023-05-12T14:24:05.389743Z",
     "iopub.status.idle": "2023-05-12T14:24:05.398861Z",
     "shell.execute_reply": "2023-05-12T14:24:05.398041Z"
    },
    "papermill": {
     "duration": 0.028394,
     "end_time": "2023-05-12T14:24:05.400955",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.372561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class decoder_transformer(nn.Module):\n",
    "    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, trg_vocab_size, max_seq_len, dropout_rate=0.1):\n",
    "        super(decoder_transformer, self).__init__()\n",
    "        self.token_embeds = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.pos_embeds = nn.Embedding(max_seq_len, d_model)\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([decoder_block(d_model, num_heads, hidden_dim, dropout_rate) \n",
    "                                    for _ in range(num_blocks)])\n",
    "    \n",
    "    def forward(self, encoder_output, target, decoder_mask=None, memory_mask=None):\n",
    "        # shape of target is (b, t)\n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "        t_embeds = self.token_embeds(target) # (b, t, d)\n",
    "        pos_ids = torch.broadcast_to(torch.arange(self.max_seq_len), (x.shape[0], self.max_seq_len)).type(torch.LongTensor\n",
    "                                                                                                         ).to(device)\n",
    "        p_embeds = self.pos_embeds(pos_ids)  # (b, t, d)\n",
    "        \n",
    "        inp = t_embeds + p_embeds\n",
    "        op = self.dropout(inp)\n",
    "        # now op is (b, t, d)\n",
    "        \n",
    "        for _, block in enumerate(self.blocks):\n",
    "            op = block(encoder_output, op, decoder_mask, memory_mask)\n",
    "            \n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acfb229f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.435574Z",
     "iopub.status.busy": "2023-05-12T14:24:05.434776Z",
     "iopub.status.idle": "2023-05-12T14:24:05.444315Z",
     "shell.execute_reply": "2023-05-12T14:24:05.443519Z"
    },
    "papermill": {
     "duration": 0.028905,
     "end_time": "2023-05-12T14:24:05.446411",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.417506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class transformer(nn.Module):\n",
    "    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, trg_vocab_size, max_seq_len, \n",
    "                dropout_rate=0.1):\n",
    "        super(transformer, self).__init__()\n",
    "        self.encoder = encoder_transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len,\n",
    "                            dropout_rate=0.1)\n",
    "        self.decoder = decoder_transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len,\n",
    "                            dropout_rate=0.1)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, trg_vocab_size)\n",
    "        self.lookahead = torch.tril(torch.ones((max_seq_len, max_seq_len))).to(device)\n",
    "    \n",
    "    def forward(self, src, trg, src_pad_mask=None, trg_pad_mask=None):\n",
    "        # we require masks to be of shape (b, 1, 1, t)\n",
    "        dec_mask = None\n",
    "        if src_pad_mask is not None:\n",
    "            src_pad_mask = src_pad_mask.unsqueeze(1).unsqueeze(1)\n",
    "            src_pad_mask = src_pad_mask.to(device)\n",
    "        if trg_pad_mask is not None:\n",
    "            trg_pad_mask = trg_pad_mask.unsqueeze(1).unsqueeze(1)\n",
    "            dec_mask = torch.minimum(trg_pad_mask, self.lookahead)\n",
    "            dec_mask = dec_mask.to(device)\n",
    "            \n",
    "        enc_op = self.encoder(src, src_pad_mask)\n",
    "        op = self.decoder(enc_op, trg, dec_mask, src_pad_mask) # op is of shape (b, t, d)\n",
    "        # and generate the required look ahead mask\n",
    "        op = op.reshape(-1, op.shape[-1]) # shape is (b*t, d)\n",
    "        op = self.fc(op) # shape is (b*t, trg_vocab_size)\n",
    "        \n",
    "        return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e5346",
   "metadata": {
    "papermill": {
     "duration": 0.017213,
     "end_time": "2023-05-12T14:24:05.480523",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.463310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab7ece99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.515301Z",
     "iopub.status.busy": "2023-05-12T14:24:05.514557Z",
     "iopub.status.idle": "2023-05-12T14:24:05.518853Z",
     "shell.execute_reply": "2023-05-12T14:24:05.518033Z"
    },
    "papermill": {
     "duration": 0.023327,
     "end_time": "2023-05-12T14:24:05.520658",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.497331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BLEU():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b7c28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.555503Z",
     "iopub.status.busy": "2023-05-12T14:24:05.554779Z",
     "iopub.status.idle": "2023-05-12T14:24:05.558751Z",
     "shell.execute_reply": "2023-05-12T14:24:05.557853Z"
    },
    "papermill": {
     "duration": 0.023397,
     "end_time": "2023-05-12T14:24:05.560660",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.537263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def METEOR():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37561591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.595013Z",
     "iopub.status.busy": "2023-05-12T14:24:05.594240Z",
     "iopub.status.idle": "2023-05-12T14:24:05.598933Z",
     "shell.execute_reply": "2023-05-12T14:24:05.598146Z"
    },
    "papermill": {
     "duration": 0.023751,
     "end_time": "2023-05-12T14:24:05.600820",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.577069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='my_checkpoint(1).pth'):\n",
    "    # will save model and optimizer params at every epoch\n",
    "    print(\"-> Saving CheckPoint\")\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5c0354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.635220Z",
     "iopub.status.busy": "2023-05-12T14:24:05.634479Z",
     "iopub.status.idle": "2023-05-12T14:24:05.639241Z",
     "shell.execute_reply": "2023-05-12T14:24:05.638435Z"
    },
    "papermill": {
     "duration": 0.023793,
     "end_time": "2023-05-12T14:24:05.641107",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.617314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint, model):\n",
    "    # it will just load, we can train it further, make changes to the architecture\n",
    "    # and simply use it to predict\n",
    "    print(\"-> Loading CheckPoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2896b52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.675410Z",
     "iopub.status.busy": "2023-05-12T14:24:05.674607Z",
     "iopub.status.idle": "2023-05-12T14:24:05.684090Z",
     "shell.execute_reply": "2023-05-12T14:24:05.683307Z"
    },
    "papermill": {
     "duration": 0.028523,
     "end_time": "2023-05-12T14:24:05.685998",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.657475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(loader, model, optimizer, scaler, scheduler, loss_fn, epoch, device=device):\n",
    "    '''\n",
    "    it is the training procedure for one epoch of the network\n",
    "    '''\n",
    "    losses = 0\n",
    "    model.train()\n",
    "    num_batches = len(loader)\n",
    "    batches = tqdm(loader) # tqdm will be used to generate progress bars\n",
    "    for idx, batch in enumerate(batches, 0):\n",
    "        src = batch[0].to(device)  # (batch_size, max_len)\n",
    "        trg_inp = batch[1].to(device)  # (batch_size, max_len)\n",
    "        trg_op = batch[2].to(device) # (batch_size, max_len)\n",
    "        src_pad_mask = batch[3].to(device) # (batch_size, max_len)\n",
    "        trg_pad_mask = batch[4].to(device) # (batch_size, max_len)\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(): # for gradient underflowing and overflowing and it makes training faster by converting all floats to float16\n",
    "            op = model(src, trg_inp, src_pad_mask, trg_pad_mask) # op shape is (batch_size*max_len, trg_vocab_size+1)\n",
    "            trg_op = trg_op.reshape(trg_op.shape[0]*trg_op.shape[1]) # trg_op shape is (batch_size*max_len)\n",
    "            loss = loss_fn(op, trg_op) # loss_fn should contain the parametere ignore_idx=0, so that \n",
    "            # losses corresponding to the padding token isn't calculated\n",
    "\n",
    "        # making all the previous gradients zero \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        batches.set_postfix(loss = loss.item(), epoch=epoch) # loss of this current batch on current iteration \n",
    "        losses+= loss.item()\n",
    "\n",
    "    losses/=num_batches    \n",
    "    #scheduler.step()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cf1ce0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.720485Z",
     "iopub.status.busy": "2023-05-12T14:24:05.719781Z",
     "iopub.status.idle": "2023-05-12T14:24:05.724099Z",
     "shell.execute_reply": "2023-05-12T14:24:05.723324Z"
    },
    "papermill": {
     "duration": 0.023376,
     "end_time": "2023-05-12T14:24:05.725966",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.702590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # i will only use this function for measuring its accuracy on different metrics\n",
    "    # for this task such as meteor and bleu\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c5c442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.760274Z",
     "iopub.status.busy": "2023-05-12T14:24:05.760008Z",
     "iopub.status.idle": "2023-05-12T14:24:05.769959Z",
     "shell.execute_reply": "2023-05-12T14:24:05.769181Z"
    },
    "papermill": {
     "duration": 0.02934,
     "end_time": "2023-05-12T14:24:05.771855",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.742515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, max_seq_len=64, trans_len=50, beam_search = None):\n",
    "    model.eval()\n",
    "    # first i am given the english sentence\n",
    "    inp = bpemb_en.encode_ids_with_bos_eos(sentence)\n",
    "    enc_mask = [1]*(len(inp))\n",
    "    inp = inp + [0]*(max_seq_len - len(inp))\n",
    "    enc_mask = enc_mask + [0]*(max_seq_len - len(enc_mask))\n",
    "    # inp shape is (max_seq_len) and so is of mask\n",
    "    #print(f'input = {inp}\\n\\nmask = {enc_mask}')\n",
    "    inp = torch.tensor(inp).unsqueeze(0).to(device) # shape of input is (1, max_seq_len)\n",
    "    enc_mask = torch.tensor(enc_mask).unsqueeze(0).to(device) # shape of mask is also (1, max_seq_len)\n",
    "    #inp =  inp.unsqueeze(0)\n",
    "    #enc_mask = enc_mask.unsqueeze(0).unsqueeze(1).unsqueeze(1) #  shape should be (b,1,1,max_seq_len)\n",
    "    # now the shapes are as required by the transformer\n",
    "    \n",
    "    #enc_op = model.encoder(inp, enc_mask)\n",
    "    # now we have to decode the sentence one-by-one \n",
    "    # so let us first of all make the inputs and the corresponding trg_mask\n",
    "    trg_inp = torch.zeros(max_seq_len).unsqueeze(0).to(device) # shape is (1, max_seq_len)\n",
    "    trg_mask = torch.zeros(max_seq_len).unsqueeze(0).to(device) # shape is (1, max_seq_len)\n",
    "    \n",
    "    #lookahead = torch.tril(torch.ones((max_seq_len, max_seq_len))).to(device) \n",
    "    \n",
    "    trg_inp[0, 0] = 1 # 1 means <sos> token\n",
    "    translation = []\n",
    "    #trg_mask[0, 0, 0, len(translation)] = 1 # as trg_inp has only one word in it at current time step\n",
    "    #dec_mask = torch.minimum(trg_mask, lookahead)\n",
    "    trg_mask[0, len(translation)] = 1 # as trg_inp has only one word in it at current time step\n",
    "    last_token = trg_inp[0, len(translation)]\n",
    "    # now we have to pass it through a decoder until we get a <eos> token or we exceed trans_len\n",
    "    while len(translation)<trans_len and last_token!=2: # 2 means <eos> token\n",
    "        # now we have to pass the above inputs through decoder\n",
    "        #dec_op = model.decoder(enc_op, trg_inp, dec_mask, enc_mask) \n",
    "        # now shape of decoder op will be \n",
    "        # shape of output is (1, hindi_vocab_size)\n",
    "        op = model(inp, trg_inp, enc_mask, trg_mask) # shape of op will be (max_seq_len, trg_vocab_size)\n",
    "#         print(op.shape)\n",
    "#         print(op)\n",
    "        \n",
    "#         op = op.argmax(dim=1)  # shape will be (max_seq_len)  Greedy decoding\n",
    "#         op = None\n",
    "        if beam_search:\n",
    "            op = beam_search(op)\n",
    "        else:\n",
    "            op = op.argmax(dim=1)\n",
    "#         print(op)\n",
    "#         op.squeeze()\n",
    "#         print(op.shape)\n",
    "        last_token = op[0][len(translation)].item()\n",
    "#         print(last_token)\n",
    "        translation.append(last_token)\n",
    "        trg_inp[0, len(translation)] = last_token  # updating the last token in the trg_inp\n",
    "        trg_mask[0, len(translation)] = 1  # setting up the mask for the current value equal to 1\n",
    "        #print(f\"DONE {len(translation)} times\")\n",
    "        \n",
    "    model.train()\n",
    "    return bpemb_hi.decode(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a38aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "def beam_search(prediction, k=5):\n",
    "#     prediction_t = list(tensor.detach().numpy(prediction_t))\n",
    "    prediction = prediction.unsqueeze(0)\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    batch_size, seq_length, vocab_size = prediction.shape\n",
    "    log_prob, indices = prediction[:, 0, :].topk(k, sorted=True)\n",
    "    indices = indices.unsqueeze(-1)\n",
    "    for n1 in range(1, seq_length):\n",
    "        log_prob_temp = log_prob.unsqueeze(-1) + prediction[:, n1, :].unsqueeze(1).repeat(1, k, 1)\n",
    "        log_prob, index_temp = log_prob_temp.view(batch_size, -1).topk(k, sorted=True)\n",
    "        idx_begin = index_temp // vocab_size  # retrieve index of start sequence\n",
    "        idx_concat = index_temp % vocab_size  # retrieve index of new token\n",
    "        new_indices = torch.zeros((batch_size, k, n1+1), dtype=torch.int64).to(device)\n",
    "        for n2 in range(batch_size):\n",
    "            new_indices[n2, :, :-1] = indices[n2][idx_begin[n2]]\n",
    "            new_indices[n2, :, -1] = idx_concat[n2]\n",
    "        indices = new_indices\n",
    "#     indices[0]\n",
    "    return indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873125a",
   "metadata": {
    "papermill": {
     "duration": 0.017105,
     "end_time": "2023-05-12T14:24:05.805506",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.788401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DRIVER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "575c18d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.840856Z",
     "iopub.status.busy": "2023-05-12T14:24:05.840097Z",
     "iopub.status.idle": "2023-05-12T14:24:05.845729Z",
     "shell.execute_reply": "2023-05-12T14:24:05.844829Z"
    },
    "papermill": {
     "duration": 0.025483,
     "end_time": "2023-05-12T14:24:05.847758",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.822275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "num_epochs =  20\n",
    "lr = 3e-4\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = CustomDataset(train_split, max_seq_len=64)\n",
    "test_dataset = CustomDataset(test_split, max_seq_len=64)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1326ab88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:05.882277Z",
     "iopub.status.busy": "2023-05-12T14:24:05.881544Z",
     "iopub.status.idle": "2023-05-12T14:24:10.835599Z",
     "shell.execute_reply": "2023-05-12T14:24:10.833001Z"
    },
    "papermill": {
     "duration": 4.974286,
     "end_time": "2023-05-12T14:24:10.838574",
     "exception": false,
     "start_time": "2023-05-12T14:24:05.864288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1              [-1, 64, 512]       5,120,512\n",
      "         Embedding-2              [-1, 64, 512]          32,768\n",
      "           Dropout-3              [-1, 64, 512]               0\n",
      "            Linear-4              [-1, 64, 512]         262,144\n",
      "            Linear-5              [-1, 64, 512]         262,144\n",
      "            Linear-6              [-1, 64, 512]         262,144\n",
      "            Linear-7              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-8              [-1, 64, 512]               0\n",
      "           Dropout-9              [-1, 64, 512]               0\n",
      "        LayerNorm-10              [-1, 64, 512]           1,024\n",
      "           Linear-11             [-1, 64, 2048]       1,050,624\n",
      "             ReLU-12             [-1, 64, 2048]               0\n",
      "           Linear-13              [-1, 64, 512]       1,049,088\n",
      "      feedforward-14              [-1, 64, 512]               0\n",
      "          Dropout-15              [-1, 64, 512]               0\n",
      "        LayerNorm-16              [-1, 64, 512]           1,024\n",
      "    encoder_block-17              [-1, 64, 512]               0\n",
      "           Linear-18              [-1, 64, 512]         262,144\n",
      "           Linear-19              [-1, 64, 512]         262,144\n",
      "           Linear-20              [-1, 64, 512]         262,144\n",
      "           Linear-21              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-22              [-1, 64, 512]               0\n",
      "          Dropout-23              [-1, 64, 512]               0\n",
      "        LayerNorm-24              [-1, 64, 512]           1,024\n",
      "           Linear-25             [-1, 64, 2048]       1,050,624\n",
      "             ReLU-26             [-1, 64, 2048]               0\n",
      "           Linear-27              [-1, 64, 512]       1,049,088\n",
      "      feedforward-28              [-1, 64, 512]               0\n",
      "          Dropout-29              [-1, 64, 512]               0\n",
      "        LayerNorm-30              [-1, 64, 512]           1,024\n",
      "    encoder_block-31              [-1, 64, 512]               0\n",
      "           Linear-32              [-1, 64, 512]         262,144\n",
      "           Linear-33              [-1, 64, 512]         262,144\n",
      "           Linear-34              [-1, 64, 512]         262,144\n",
      "           Linear-35              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-36              [-1, 64, 512]               0\n",
      "          Dropout-37              [-1, 64, 512]               0\n",
      "        LayerNorm-38              [-1, 64, 512]           1,024\n",
      "           Linear-39             [-1, 64, 2048]       1,050,624\n",
      "             ReLU-40             [-1, 64, 2048]               0\n",
      "           Linear-41              [-1, 64, 512]       1,049,088\n",
      "      feedforward-42              [-1, 64, 512]               0\n",
      "          Dropout-43              [-1, 64, 512]               0\n",
      "        LayerNorm-44              [-1, 64, 512]           1,024\n",
      "    encoder_block-45              [-1, 64, 512]               0\n",
      "encoder_transformer-46              [-1, 64, 512]               0\n",
      "        Embedding-47              [-1, 64, 512]       5,120,512\n",
      "        Embedding-48              [-1, 64, 512]          32,768\n",
      "          Dropout-49              [-1, 64, 512]               0\n",
      "           Linear-50              [-1, 64, 512]         262,144\n",
      "           Linear-51              [-1, 64, 512]         262,144\n",
      "           Linear-52              [-1, 64, 512]         262,144\n",
      "           Linear-53              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-54              [-1, 64, 512]               0\n",
      "          Dropout-55              [-1, 64, 512]               0\n",
      "        LayerNorm-56              [-1, 64, 512]           1,024\n",
      "           Linear-57              [-1, 64, 512]         262,144\n",
      "           Linear-58              [-1, 64, 512]         262,144\n",
      "           Linear-59              [-1, 64, 512]         262,144\n",
      "           Linear-60              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-61              [-1, 64, 512]               0\n",
      "          Dropout-62              [-1, 64, 512]               0\n",
      "        LayerNorm-63              [-1, 64, 512]           1,024\n",
      "           Linear-64             [-1, 64, 2048]       1,050,624\n",
      "             ReLU-65             [-1, 64, 2048]               0\n",
      "           Linear-66              [-1, 64, 512]       1,049,088\n",
      "      feedforward-67              [-1, 64, 512]               0\n",
      "          Dropout-68              [-1, 64, 512]               0\n",
      "        LayerNorm-69              [-1, 64, 512]           1,024\n",
      "    decoder_block-70              [-1, 64, 512]               0\n",
      "           Linear-71              [-1, 64, 512]         262,144\n",
      "           Linear-72              [-1, 64, 512]         262,144\n",
      "           Linear-73              [-1, 64, 512]         262,144\n",
      "           Linear-74              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-75              [-1, 64, 512]               0\n",
      "          Dropout-76              [-1, 64, 512]               0\n",
      "        LayerNorm-77              [-1, 64, 512]           1,024\n",
      "           Linear-78              [-1, 64, 512]         262,144\n",
      "           Linear-79              [-1, 64, 512]         262,144\n",
      "           Linear-80              [-1, 64, 512]         262,144\n",
      "           Linear-81              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-82              [-1, 64, 512]               0\n",
      "          Dropout-83              [-1, 64, 512]               0\n",
      "        LayerNorm-84              [-1, 64, 512]           1,024\n",
      "           Linear-85             [-1, 64, 2048]       1,050,624\n",
      "             ReLU-86             [-1, 64, 2048]               0\n",
      "           Linear-87              [-1, 64, 512]       1,049,088\n",
      "      feedforward-88              [-1, 64, 512]               0\n",
      "          Dropout-89              [-1, 64, 512]               0\n",
      "        LayerNorm-90              [-1, 64, 512]           1,024\n",
      "    decoder_block-91              [-1, 64, 512]               0\n",
      "           Linear-92              [-1, 64, 512]         262,144\n",
      "           Linear-93              [-1, 64, 512]         262,144\n",
      "           Linear-94              [-1, 64, 512]         262,144\n",
      "           Linear-95              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-96              [-1, 64, 512]               0\n",
      "          Dropout-97              [-1, 64, 512]               0\n",
      "        LayerNorm-98              [-1, 64, 512]           1,024\n",
      "           Linear-99              [-1, 64, 512]         262,144\n",
      "          Linear-100              [-1, 64, 512]         262,144\n",
      "          Linear-101              [-1, 64, 512]         262,144\n",
      "          Linear-102              [-1, 64, 512]         262,656\n",
      "MultiHeadSelfAttention-103              [-1, 64, 512]               0\n",
      "         Dropout-104              [-1, 64, 512]               0\n",
      "       LayerNorm-105              [-1, 64, 512]           1,024\n",
      "          Linear-106             [-1, 64, 2048]       1,050,624\n",
      "            ReLU-107             [-1, 64, 2048]               0\n",
      "          Linear-108              [-1, 64, 512]       1,049,088\n",
      "     feedforward-109              [-1, 64, 512]               0\n",
      "         Dropout-110              [-1, 64, 512]               0\n",
      "       LayerNorm-111              [-1, 64, 512]           1,024\n",
      "   decoder_block-112              [-1, 64, 512]               0\n",
      "decoder_transformer-113              [-1, 64, 512]               0\n",
      "          Linear-114                [-1, 10001]       5,130,513\n",
      "================================================================\n",
      "Total params: 37,492,497\n",
      "Trainable params: 37,492,497\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 37.33\n",
      "Params size (MB): 143.02\n",
      "Estimated Total Size (MB): 180.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model hyperparameters\n",
    "num_blocks = 3\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "hidden_dim = 4*d_model\n",
    "src_vocab_size = bpemb_en.vocab_size + 1 # +1 due to padding token\n",
    "trg_vocab_size = bpemb_hi.vocab_size + 1 # +1 due to padding token\n",
    "max_seq_len = 64\n",
    "\n",
    "# testing the model\n",
    "model = transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, \n",
    "                              trg_vocab_size, max_seq_len).to(device)\n",
    "summary(model, [(max_seq_len, ), (max_seq_len ,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9baeb5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:10.874175Z",
     "iopub.status.busy": "2023-05-12T14:24:10.873867Z",
     "iopub.status.idle": "2023-05-12T14:24:10.926560Z",
     "shell.execute_reply": "2023-05-12T14:24:10.925431Z"
    },
    "papermill": {
     "duration": 0.072713,
     "end_time": "2023-05-12T14:24:10.928662",
     "exception": false,
     "start_time": "2023-05-12T14:24:10.855949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English Sentence ['it is if we have handed the keys to the vault over to burglars. ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ ']\n",
      "\n",
      "Original Hindi Sentence ['यह ऐसा है जैसे हमने खजाने की चाबी चोरों को दे दी हो। ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ ']\n",
      "\n",
      "Predicted Sentence ['स्पेनिश', 'रि', 'ंखला', 'पुष्प', 'संग', '्मण', 'ण्ड', 'अञ्चल', 'नात', 'ष्णा', 'उपयोग', 'कोयला', 'hys', 'अभिक्रिया', 'भर', 'णी', 'ca', 'ोर्ट', 'यूक', 'शियम', '0000–00', 'गुण', 'जैविक', 'रियल', 'अवत', 'भ्रूण', 'cr', 'क्षम', 'वनडे', 'देखने', 'आश', 'ट्ट', 'ent', 'बीन', 'जन्मे', 'जैविक', '२०१५', 'क्षम', 'mat', 'प्रयास', 'प्रेस', 'eric', 'प्रयास', 'पृष्ठभूमि', 'शास', 'भ्रूण', 'city', 'मंच', 'राहुल', 'अवत', 'केल', 'apse', 'अंग्रेज़ी', 'इत', 'अंग्रेज़ी', 'ण', 'ry', 'प्रयास', 'एल', 'सफल', 'कथित', '२०००', 'हिन्दु', 'जा']\n"
     ]
    }
   ],
   "source": [
    "# let us test our model on some actual input to check it doesn't break\n",
    "for _, batch in enumerate(train_loader):\n",
    "    src = batch[0][0].unsqueeze(0).to(device)\n",
    "    trg_inp = batch[1][0].unsqueeze(0).to(device)\n",
    "    trg_op = batch[2][0].unsqueeze(0).to(device)\n",
    "    src_pad_mask = batch[3][0].unsqueeze(0).to(device)\n",
    "    trg_pad_mask = batch[4][0].unsqueeze(0).to(device)\n",
    "    break\n",
    "    \n",
    "#print(f'{src}\\n\\n{src_pad_mask}\\n\\n{trg}\\n\\n{trg_pad_mask}')\n",
    "op = model(src, trg_inp, src_pad_mask, trg_pad_mask)\n",
    "op = nn.Softmax(dim=-1)(op)\n",
    "out = torch.max(op, dim=-1).indices\n",
    "print(f'Original English Sentence {bpemb_en.decode(src.tolist())}\\n\\nOriginal Hindi Sentence {bpemb_hi.decode(trg_inp.tolist())}\\n\\nPredicted Sentence {bpemb_hi.decode(out.tolist())}')\n",
    "# ?? are because of the padding tokens we can easily remove them when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce9163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:10.964345Z",
     "iopub.status.busy": "2023-05-12T14:24:10.963450Z",
     "iopub.status.idle": "2023-05-12T14:24:11.325239Z",
     "shell.execute_reply": "2023-05-12T14:24:11.323760Z"
    },
    "papermill": {
     "duration": 0.381988,
     "end_time": "2023-05-12T14:24:11.327520",
     "exception": false,
     "start_time": "2023-05-12T14:24:10.945532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exampel of translated sentence\n",
    "text = 'the aluminium corporation of india, came into existence after the war.'\n",
    "print(translate_sentence(text, model, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "291354cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:11.363616Z",
     "iopub.status.busy": "2023-05-12T14:24:11.363301Z",
     "iopub.status.idle": "2023-05-12T14:24:11.369852Z",
     "shell.execute_reply": "2023-05-12T14:24:11.368955Z"
    },
    "papermill": {
     "duration": 0.026781,
     "end_time": "2023-05-12T14:24:11.371746",
     "exception": false,
     "start_time": "2023-05-12T14:24:11.344965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setups\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0) \n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "losses = []\n",
    "# for inference\n",
    "# sentences = ['another plant, the aluminium corporation of india, came into existence after the war.', \n",
    "#              'He is doing very good these days', 'this guy is totally mad', 'what were you saying that day?']\n",
    "sentences = [\"So what happened on this day?\", \n",
    "             'Allow all sites to track my physical location', \n",
    "             'India is a democratic country', \n",
    "             \"In 1898, Sarojini Naidu became the life - partner of Dr. Govindarajulu Naidu.\", \n",
    "             'Is this a good time?',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model pickle\n",
    "model.load_state_dict(torch.load(\"my_checkpoint (1).pth\")['state_dict'])\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9da86b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:11.407106Z",
     "iopub.status.busy": "2023-05-12T14:24:11.406359Z",
     "iopub.status.idle": "2023-05-12T14:24:11.411372Z",
     "shell.execute_reply": "2023-05-12T14:24:11.410564Z"
    },
    "papermill": {
     "duration": 0.024696,
     "end_time": "2023-05-12T14:24:11.413292",
     "exception": false,
     "start_time": "2023-05-12T14:24:11.388596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taking the test sentences for checking how good the model is trained\n",
    "def infer(sentences, model, max_seq_len, beam_search = None):\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        print(f\"Example {idx+1}:\\n{sentence}\\n{' '.join(translate_sentence(sentence, model, max_seq_len, beam_search = beam_search))}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92118fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:11.448578Z",
     "iopub.status.busy": "2023-05-12T14:24:11.448315Z",
     "iopub.status.idle": "2023-05-12T14:24:12.896091Z",
     "shell.execute_reply": "2023-05-12T14:24:12.894578Z"
    },
    "papermill": {
     "duration": 1.468068,
     "end_time": "2023-05-12T14:24:12.898343",
     "exception": false,
     "start_time": "2023-05-12T14:24:11.430275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "So what happened on this day?\n",
      "तो इस दिन में कोई पड़ा तो ? \n",
      "\n",
      "\n",
      "Example 2:\n",
      "Allow all sites to track my physical location\n",
      "सभी साइट ों को स्वचालित ट्रैक बां ट ें \n",
      "\n",
      "\n",
      "Example 3:\n",
      "India is a democratic country\n",
      "भारत एक लोक तांत्रिक देश है \n",
      "\n",
      "\n",
      "Example 4:\n",
      "In 1898, Sarojini Naidu became the life - partner of Dr. Govindarajulu Naidu.\n",
      "0000 में सर ोज िनी नाय डू डा . गोवि ंद राज ुल ू नाय डू की जीवन - संग िनी बनी ं । \n",
      "\n",
      "\n",
      "Example 5:\n",
      "Is this a good time?\n",
      "यह एक अच्छा समय है ? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer(sentences, model, max_seq_len, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c11eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:24:12.934776Z",
     "iopub.status.busy": "2023-05-12T14:24:12.934483Z",
     "iopub.status.idle": "2023-05-12T14:43:03.806757Z",
     "shell.execute_reply": "2023-05-12T14:43:03.805296Z"
    },
    "papermill": {
     "duration": 1130.89279,
     "end_time": "2023-05-12T14:43:03.808868",
     "exception": false,
     "start_time": "2023-05-12T14:24:12.916078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses.append(train(train_loader, model, optimizer, scaler, scheduler, loss_fn, epoch))\n",
    "    \n",
    "    # save checkpoint\n",
    "    checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict()\n",
    "    }\n",
    "    save_checkpoint(checkpoint)\n",
    "    \n",
    "    # check accuracy  on test set\n",
    "    infer(sentences, model, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e547a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T14:43:08.226061Z",
     "iopub.status.busy": "2023-05-12T14:43:08.225670Z",
     "iopub.status.idle": "2023-05-12T14:43:08.230521Z",
     "shell.execute_reply": "2023-05-12T14:43:08.229454Z"
    },
    "papermill": {
     "duration": 1.142638,
     "end_time": "2023-05-12T14:43:08.233027",
     "exception": false,
     "start_time": "2023-05-12T14:43:07.090389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to perform good translation, we can do the following - \n",
    "# get more data, first try with some shorter sentences (or to check if transformer works well, take small data, try\n",
    "# overfitting it)\n",
    "# train it for longer time and schedule the learning rate as given in the paper\n",
    "# use in built nn.Transformer class "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1215.24457,
   "end_time": "2023-05-12T14:43:15.683122",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-12T14:23:00.438552",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
